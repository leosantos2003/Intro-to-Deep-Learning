# Lesson 3

`lesson_3`: stochastic gradient descent; using Keras and Tensorflow to train the first neural network.

<div style="display: flex; justify-content: center;">
<div class="texto-titulo">

## Graphic 1:
* Compares the Loss with the increase of Epochs.
* The loss is decreasing alongside the increase of Epochs because the model is learning. Each epoch is an opportunity for it to adjust its internal parameters (weights and biases) to make increasingly better predictions and, consequently, make fewer errors.
* It stabilizes and becomes a nearly horizontal line at the end of training, because at this point the model has already learned the main pattern of the data and can no longer significantly improve.

</div>
      <img style="width: 48%;" width="1000" height="600" alt="training_loss_graphic" src="https://github.com/user-attachments/assets/468f3a54-d6ff-4f6e-9594-adef06a8d923" />
</div>
